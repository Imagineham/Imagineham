Chapter 1
	C programming language 1969 1973
	Stdlib 1989
	C was made for Unix- practical
	From program to execution- 4 phases - Compilation
		Pre-processor -> READ # files so stdio.h or stdlib.h Results in .i
		Compiler -> translates into assembly Results in .s
		Assembler -> machine-language instructions, .o files are bits read by machines not us
		Linker -> links called functions, printf from printf.o, Results in executable
	
	Optimization! Good programmers know why some functions work better than others
	Buses -> (USB = Universal Serial Bus) used to transfer fixed sized bytes, words
	I/O -> Input/Output like I/O shield for motherboard (connects to external world)
DRAM => Dynamic Random Access Memory, lines of bytes called arrays unique addresses *(pointers). 
Register-> storage device
CPU -> Central Processing Unit (the brain), repeats basic instruction over and over
	Load -> copy into register
	Save -> copy from register
	Update -> copy contents of two registers, ALU adds, copy result in a register
	I/O Read -> Copy from I/O into register
Caches -> temporary memory, used to quicken compilation bc info does not need to travel to *main memory. A Cache using a bus to the CPU is faster, a cache in the CPU is fastest. 

Storage Device Hierarchy
*L0, L1, L2, etc/ Levels. Higher the number, the slower
*list below L0 = Register, increases down
Register
On-chip cache
Off chip cache
Main memory (DRAM)
Local storage
Remote storage (Web servers) 

Operating System (Windows, Linux, Mac)

Practice Prob 2.1
	Dec     Binary         Hex
	0       00000000       00
	55      00110111       37
	136     10001000       88
	243     11110011       F3
	82      01010010       52
	172     10101100       AC
	231     11100111       E7
	167     10100111       A7
	62      00111110       3E
	188     10111100       BC

Practice Prob 2.5
	a        01101001
	b        01010101
	~a       10010110
	~b       10101010
	a & b    01000001
	a | b    01111101
	a ^ b    00111100

Practice Prob 2.9
	x = 0x66 = 01100110
	y = 0x93 = 10010011

	x & y =    00000010 
	x | y =    11110111
	~x | ~y =  11111101
	x & !y =   00000000

	x && y =   00000001
	x || y =   00000001
	!x || !y = 00000000
	x && ~y =  00000001

Practice Prob 2.11	
	x		x << 3	 	[Log]x >> 2		[Arith]x >> 2
	0xF0    10000000	00111100		11111100
			0x80		0x3C			0xFC
	0x0F	01111000	00000011		00000011
			0x7C		0x03			0x03
	0xCC	01100000	00110011		11110011
			0x60		0x33			0xF3
	0x55	10101000	00010101		00010101
			0xA8		0x15			0x15

Practice Prob 2.12
		B2U		B2T
	0	0000	0
	3	0011	3
	8	1000	-8
	A	1010	-6
	F	1111	-1

Practice Prob 2.15

OgHex	TruncHex		OgU		TU 		OgT2		T2 	
0=0000	0=000			0=0000	0=000	0=0000		0=000				
3=0011	3=011			3=0011	3=011	3=0011		3=011				
8=1000	0=000			8=1000	0=000	-8=1000		0=000				
A=1010	2=010			10=1010	2=010	-6=1010		2=010				
F=1111	7=111			15=1111	7=111	-1=1111		-1=111				

Practice Prob 2.17

Hex		Decimal		Decimal		Hex
0=0000	0			0			0
3=0011	3			13			D=1101
8=1000	8			8			8=1000
A=1010	10			6			6=0110
F=1111	15			1			1=0001			

Practice Prob 2.18

x		y		x + y 		x + 4y		Cache
10000	10101	100101
10000	10000	100000
11000	00111	11111
11110	00101	11011
01000	01000	10000


Practice Prob 2.19




Chapter 3
	Assembly

	Pre-processor -> READ # files so stdio.h or stdlib.h Results in .i
	Compiler -> translates into assembly Results in .s
	Assembler -> machine-language instructions, .o files are bits read by machines not us
	Linker -> links called functions, printf from printf.o, Results in executable

	"the assembly programmer's view of the machine differs significantly from that of a C programmer"
		program counter -> (percent)-eip indicated address in memory
		integer register -> 8 locations, stores 32 bits; hold pointers for programs/local variables/etc 
		condition code -> status info, most recent executed arithmetic (ex. if else)
		floating-point -> 8 locations, floats

		machine instructions -> SIMPLE, add numbers, transfer data (ex. movl, subl, shrl...)

	Assembly HW3 Code example (97 in textbook) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

	SIMPLE.C ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		int simple (int *xp, int y) {
			int t = *xp + y;
			*xp = t;
			return t;
		}
	|
	|
	|
	v
	SIMPLE.S (COMPILER)	~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		.globl simple
		  .type		simple,@function
		simple:
			pushl %ebp				Save frame Pointer		these are the instructions	
			movl %esp, %ebp			Create new pointer		you worked on for homework	
			movl 8 (%ebp), %eax 	Get xp					see page 100. Helpful to 
			movl (%eax), %edx		Retrieve *xp			memorize!!!
			addl 12(%ebp), %edx		Add y to get t		
			movl %edx, %eax			Store t as *xp				
			movl %edp, %esp			Set t as return val					
			movle %edp				reset stack pointer
			popl %edp				Reset frame pointer
			ret						%return
		.Lfel:
		  .size		simple,.Lfel-simple
		  .ident	"GCC: (GNU) 2.95.3 20010315 (release)"

	lines that start with  . direct assembler and Linker


	DATA TYPES
		char 					(1 byte) 					(8 bits)
		char 				8 (string -> 4 bytes) 			(32 bits)
		int 					4 bytes 					(32 bits)
		float 			"single precision" (4 bytes) 		(32 bits)
		double 			"double precision" (8 bytes) 		(64 bits)
		extended-precision 		(10 bytes) 					(80 bits)
		long double 			(12 bytes) 					(96 bits)

	ACCESSING INFORMATION
		SEE PAGE 100 FOR TABLE

			Imediate -> Constant Values -> $-577 $0x1f 
			Register -> %ebp, %esp, %rdi, %rax, etc -> three letters have 32 bits 
			Memory -> memory reference, accesses memory at the effective address

			movb vs vs movw vs movl vs movbl
				movb-> moves a single byte (char, b stands for byte, 8 bit)
				movw-> moves two bytes (w stands for word, 16 bit)
				movl-> moves 4 bytes (l stands for double word, 32 bit)
				movsbl-> from 1 byte to 4, adds 24 leadings 1's 
				movzbl-> from 1 byte to 4, adds 24 leading 0's

			Load Effective Address (leal) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				variant of movl
				function: COPIES EFFECTIVE Address	
					ex: leal 7, assume %edx = x; 
								(%edx, %edx, 4). = 7 + %edx + %edx * 4 = 5x + 7;
					
			sall, shll, sarl, shrl
				sall -> LEFT SHIFT, 0'S
				shll -> LEFT SHIFT, 0'S

				*sarl -> RIGHT SHIFT, ARITHMETIC 
				*shrl -> RIGHT SHIFT, LOGICAL 

	CONTROL

		Condition Codes
			CPU maintains single-bit condition code registers describing the most recent operation

			CF: CARRY FLAG -> most recent operation carried most significant bit-> overflow
			ZF: ZERO FLAG -> most recent operation returned 0
			SF: SIGN FLAG -> most recent operation returned a negative Values
			OF: OVERFLOW FLAG -> most recent operation caused Two's complement overflow, either positive or negative

			ex: say t = a + b

			CF = (unsigned t) < (unsigned a);
			ZF = t == 0;
			SF = t < 0;
			OF = (a < 0 == b < 0) && (t < 0 != a < 0)

			Logical Operators such as xorl, CF and OF are set to 0!!!

	ACCESSING CONDITION CODES 
		"set an integer register" -> sets a single byte to 0 or 1 based on condition Codes
		consider Condition Codes and Implicit Setting a SIDE EFFECT

			sete; For t = a-b, when a = b, t = 0, ZF is set

		SEE FIGURE 3.9 PAGE 112 FOR SET INSTRUCTIONS 
			some example:
				sete D == D <-- ZF (zero flag) == Equal/Zero 
				sets D == D <-- SF (signed flag) == negative
				setns D == D <-- ~SF == Nonnegative 
				setg D == D <-- ~(SF ^ OF) & ~ ZF == Greater than (>)
				setge D == D <-- ~(SF ^ OF) == Greater than or equal to (>=)




		CONDITION CODE EXAMPLE (let a be in %eax, b be in %edx)
			cmpl %eax,%edx			compare a:b
			setl %al				Set low order bytes of %eax to 0 or 1
			movzbl %al,%eax			set remaining bytes of %eax to 0

			Explicit Setting test
				testq Src2, Src1 -> destination is condition code
				testq b, a = a&b without setting destination
				compq Src2, Src1
				compq b, a = a-b without settinng destination 

	Practice Problem 3.7




	CONDITIONAL BRANCHES -> JUMP INSTRUCTIONS	
		jump instruction s== assembly if then else statements
			Usually instructions follow each other in order, however, jump causes the execution	
			to switch to a new order as indicated by a label. 
				labels look like .Li 

			example:
				xorl %eax,%eax				Set %eax to 0
				jmp .Li 					%"goto" .Li
				movl (%eax), %edx			This line is skipped over because jmp
			.Li 
				pop1 %edx

		DIRECT VS INDIRECT JUMPING 
			DIRECT~~~~~~~~
				jmp label -> takes you directly to a label, the label is always encoded as part of
				the instructions
			INDIRECT~~~~~~~~
				jmp *%eax  -> 		the value in register %eax becomes jump target
				jmp *(%eax) -> 		the value in memory becomes the jump target

	Practice Problem 3.8

	CONDITIONAL BRANCHES	
		regular Code in C~~~~~~~~~~~~~~~~~~~
		int absdiff(int x, int y) {
			if (x < y) {
				return y - x; 							%if x < y return y - x to get noneg value
			} else {
				return x - y;							%if x is not < y, return x - y to get nonneg value
			}
		}
		Goto Code in C~~~~~~~~~~~~~~~~~~~~~~
			int gotodiff(int x, int y) {
				int rval;								%define local variable "return value"						

				if (x < y) {							%if x < y, JUMP TO LESS, skip the code right below where
					go to less;							%rval = x -y
				rval = x - y;
				goto done;								%jump to done so you can return rval
				}
				less:									%jmp instruction target  if x < y is true
					rval = y - x;
				done:
					return rval;
			}

		example from lecture:

		val = Test ? Then_Exp : Else_Expr;

		GoTo Version
			ntest = !Test;
			if (ntest) goto Else;				%INVERT NTEST	
			val = Then_Expr;
			goto Done;
		Else:
			val = Else_Expr;
		Done:
			....


	Practice Problem 3.9

	DO-WHILE, WHILE, FOR LOOPS WILL BE DONE ON PAPER. PRACTICE PROBLEM ANSWERS HERE ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

	Memory Hierarchy 6.1 --> 6.5~~~~~~~~~~~~~~~~~~~~~~~~
		Microarchitetcure
			does not affect software infrastructure

		ISA VS Microarchitecture
			instruction set architecture -> DOES FUNCTION WORK?
				--> programmer visible state, does not change when adding caches
				--> i can see stack, i can see program counter, can see code. 
						%registers, code, memory addresses, assembly, etc ISA
			Microarchitecture ->  PERFORMANCE, HOW DOES FUNCTION WORK
				--> everytime you buy a new processor, microarchitecture is different
						%cache, valid bits, tags, conflict, hits, misses MICRO

		Elements of Program Performance
			Memory Operators x Memory Time
			ALU Ops x ALU Time (bits operations)
		+	Cond Ops x Cond Time
		=		Total Time
		aka "the time of any operation is the time it takes to access instruction memory + the time 
		it takes to perform the operation (which can be another memory access). 

		the time of memory operation is the time it takes to access data memory + instruction memory. 

		CPU-Memory Gap
			DRAM (memory) --> does not improve as fast as CPU, could be about 100 times slower than CPU
			Disk, SSD much slower than DRAM

		MEMORY Hierarchy	
			L0: Registers (x86-64 == 16 regs, each 8 bytes)   			%SMALLEST FASTEST, MOST EXPENSIVE%
			L1: Cache (SRAM, holds lines from L2 cache)
			L2: Cache (SRAM, holds lines from L3 cache)
			L3: Cache (SRAM, holds lines DRAM)
			L4: Main Memory (DRAM, 8, 16, GB of memory, much bigger than registers)
			L5: Local Secondary Storage
			L6: Remote Secondary Storage (internet)						%lARGEST, SLOWEST, CHEAPEST%

			Each Lk serves as a cache for L(k + 1)!!!
		Processor <----> Cache <----> DRAM

			CAPACITY === register << cache << DRAM
			Speed === Register >> cache >> DRAM

			if data is "in fast memory" low latency access
			if data is "not in fast memory long" latency DRAM
				
		Locality *ALL PROGRAMS HAVE LOCALITY*
			(how much locality you have...)
			programs use data and instructions with addresses near or equal to those used recently

			Temporal Locality	
				recently referenced items likely to be referenced again

			Spatial Locality	
				items with nearby addresses tend to be referenced around the same time

			MAKING CLAIMS ABOUT LOCALITY
				understanding how differences in code affect locality
				ex:
					--->for (j = 0; j < N; j++) {
					--->	for (i = 0; i < M; i++) {
							sum += a[i][j]
							}
						}

					VS 

					--->for (i = 0; i < M; i++) {
					--->	for (j = 0; j < N; j++) {
							sum += a[i][j]
							}
						}
					EXAMPLE 2 has better locality because j is the faster changing array dimension in the multi-d
					array ex. The C programming language was made with ROW major order so for continuous accesses 
					in memory. change the rightmost reference always. 

			-->stride-k reference patterns (visiting kth variable) stride-1 ref pattern (continguous) have 
					good spatial localiity
			-->loops have good temporal and spatial locality, SMALLER THE BODY AND GREATER NUMBER OF ITERATIONS THE better

			PRACTICE PROBLEM 6.5
				--->clear1 good temporal locality, good spatial locality. stride-1 ref per struct and row-major ordering 
				--->clear2 good temporal but poor spatial. Each p[i] iterated over once but within each struct hops around.  
				--->clear3 poor spatial and temporal locality. --> goes against row-major ordering, and hops around

			LOCALITY AND MEMORY
				ISA === Processor (Instruction set architecture)
					*processor, cache relationship controlled by compiler
				Microarcitecture === L1, L2, L3 caches + DRAM

		CACHE 
				cache ---> small, fast, expensive 
				DRAM ---> large, slow, cheap 
				
				Data is copied using cache blocks. Cache blocks are 64 bytes in size
				Data is always copied back and forth using transfer units

				"hit" ---> Processor asks for data in block 14, if data is in cache HIT
					  ---> looking for d in k + 1, looks for it in k first. if its in k, HIT

				"miss"---> Processor asks for data in block 12, if data is NOT in cache, MISS
								  IF THERE IS A MISS, MUST MOVE ONTO MEMORY, PUT ONTO CACHE, KICK SOMETHING OUT 
									  THEN PROCESSOR GETS BLOCK 12. 
					  --->


				cache exploiting locality == #hits/#accesess 
				cache failing to exploit locaclity == #misses/#accesses

				Memory to Register mov
					Processor loads request to cache
					check if request is in cache

						IF IT IS -----> hit, return copy of data
						IF IT IS NOT -> miss, read from main memory, replace block in cache with new, return copy

PAGE 306 CACHE DESIGN 	
			S === sets, 2^s (number of bits used, log S) sets. 
			E === blocks; lines per set think of the rectangles 
			B === bytes per cache blocks (usually 64); 2^b bytes per cache block

			valid bit (rly small) mustbe valid for hit
			tag (rly small)

			C (cache size) === S x E x B
			t (tag bits) === number of address bits - (block offset bits + set index bits)
			b (block offset bits) === log_2 B (block size in bytes)
			s (set index bits) === log_2 S (num of sets)

			Types of cache DESIGN
			--->Direct-mapped cache (E === 1)
					because  e is 1, one block per set,
				PRO: each block, there is only one place it can go; SIMPLE
				CON: restrictive, sometimes conflict 	
			--->2-way set associative cache (E === 2)
					there are two blocks per set
					first -> index set
							-> compare tag to both blocks
							-> find tag that matches
							-> if match, take block offset bits etc etc
				PRO: now we have a choice over which block to evict on a miss
				CON: search all blocks per set for tag 
			---> Direct == more cache misses, Simpler
				 fully associative == must search all locations for match, less misses, more complex

			***BLOCKS AND WRITES***
				BLOCK how to replace
					no choice in direct
					associative --> random, least recently used, first in first out! (keep track of oldest block)

				WRITE
					write through --> write to memory, higher traffic simple DESIGN
					write back --> only update copy in cache; DIRTY COPY (different)

			Miss Rate vs Hit Time vs miss Penalty
			miss rate --> misses/accesses OR  1 - hit rate; typical numbers = 3-10 percent L1
			Hit time --> time to deliver a line in cache; typical = 4 clock cycles for L1, 10 clock cycles for L2
			miss penalty --> time required bc of miss; typical 150-500 for main memory

			THE THREE C'S
			COMPULSORY/COLD ---> first reference to block (when there's nothing in cache to match anyways)
									if the cache has been warmed up, compulsor misses won't happen (as much)!
			CAPACITY ---> cache is too small to hold all data needed at a time (the working set)
			CONFLICT ---> misses due to collisions 
							ex: say blocks at level k + 1 must be replaced in block k. block i in k + 1 corresponds to 
									block (i mod 4) at k. so 0, 4, 8, 12 correspond to block 0, 5, 9, 13 block 1 etc tec.
							ex: blocks 0 and 8 go in the same place on the cache but if requested while alternating they 
									will keep missing

						

	CACHE BEHAVIOR
		memory address, 64 bit
			the blocks we have been looking at are interpreted ascii

					tag	|	set index |	off set

				Offset == b bits (B = 2^b bytes per block)
				Set Index == s bits (S = 2^s cache sets; ex: 2 way set, S = 2, so s = 1 (one bit))
				Tag bits (Address size - b - s, usually the left most leftover)

		1) locate set
		2) check tag
		3) if tag matches, and valid is set, HIT, locate data at offset 		
 

	6.1 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		RAM --> Random Access Memory
		SRAM --> Static Random Access Memory	
						Inverted pendulum, data can be kept indefinitely with stable left and 
						stable right statuses. FASTEST
		DRAM --> Dynamic Random Access Memory, uses supercells to organize bits. 
					d supercells x w cells (bits) ==> d x w = total info
					supercells organized by rows and columns. r x c == d
		DDR SDRAM --> fastest DRAM

		READS vs WRITES 
			read -> transfers data from main memory TO CPU
			write -> transfers data from CPU TO main memory

			Ex: mov A, %eax
					1) CPU inititaes read. Address of A on system bus (CPU <--> I/O)
					2) system bus transfers to I/o which transfers to memory (SYSTEM <--> I/O <--> MEMORY)
					3) Main memory reads addresson memory bus, fetches data, writes data to bus	
							(MEMORY BUS <--> DRAM)
					4) I/O carries signal from memory bus back to system bus. CPU reads from system 


		DISKS
			Disks store a lot of INFORMATION
PAGE 286 		DISK Capacity = bytes/sector x avg # sectors/track x # tracks/surface x #surfaces/platter x #platter/disk
				Like a record player, disk with magnetic surface, read/write head on arm 

PAGE 295 
	LOCALITY 		

	BOMB PROJECT NOTES~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	__gconv_transform_ascii_internal
			transform_internal_ascii
					ucs2
					ucs2reverse
					ucs4
					ucs4le
					utf8
					ucs2_internal
					ucs2reverse_internal
					ucs4_internal


		DIRECT MAPPED CACHE IN ACTION
			--> Let S = 4 ---> s = log_ 2 4 = 2
			--> Let E = 1 ---> direct mapped, one line per set
			--> Let B = 2 ---> b = log_2 2 = 1
			--> Let m = 4 ---> t = m - (b + s) -> t = 1


			Set		Valid 		Tag		block[0]		block[1]
			0		1			0		m[0]			m[1]			%4 bits, 1 byte, from 0 to 1
			1		0									
			2		1			1		m[12]			m[13]	
			3		0										

			1) Address 0, given 0. Compulsory miss
			2) Address 1, given 1. hit. index matches, valid and tag match. 
			3) Address 13, given 13. Compulsory miss. 
			4) Address 8, given 8. Miss, tag doesnt match
			5) Address 0, given 9. Conflict miss, WE JUST TOOK IT OUT AND WE HAD SPACE -_-

		SET ASSOCIATIVE CACHES
			1 < E < C/B
			ex: E = 2 --> 2 way set associative cache
				E = 4 --> 4 way set associative cache

			Each set has E lines of blocks. Functionally the same, cache just searches 
					for line with matching tag 

		Practice Problem 6.9
		
	CALLER VS CALLEE SAVE REGISTERS 
		-->Caller : %eax %edx %ecx
		-->Callee : %ebx %esi % edi


	Arrays 
		-->Remember arrays are contiguous, their size can be determined by L * sizeof (T) bytes




			



			










		














